---
title: "Download SHARKdata"
author: "Anders Torstensson"
date: '2022-03-10'
params:
  shark_datasets: "list_of_datasets.txt"
  shark_species: "shark_species_list.txt"
  worms_species: "taxa_worms.txt"
  shark_translate: "translate_headers.txt"
  shark_translate_station_names: "translate_station_names.txt"
  encoding: "utf8"
output: html_document
---

This script will download the data packages listed in "list_of_datasets.txt" from Sharkdata (https://sharkdata.smhi.se/) when you click **Knit**. The script will cache previous downloads, and will only update them if the data packages has been changed on Sharkdata.

## R Settings

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(jsonlite)
library(plyr)
library(tidyverse)

sharkDir = "../../data/shark_download"
phytoplanktonDir = "../../data/shark_phytoplankton"
picoplanktonDir = "../../data/shark_picoplankton"
hydrographyDir = "../../data/shark_hydrography"
chlorophyllDir = "../../data/shark_chlorophyll"
```

## Setup SHARKdata cache validation

```{r shark_cache_setup, echo=FALSE}
list_of_dataset = read.delim(file.path(sharkDir, params$shark_datasets), sep = "\t", header = TRUE)

datasets = fromJSON('https://sharkdata.smhi.se/datasets/list.json') %>%
  filter(dataset_name %in% list_of_dataset$dataset)

datasets_cache = c()

for(i in 1:length(unique(datasets$datatype))) {
  datasets_cache = tryCatch({
    rbind(datasets_cache, 
          read.table(file.path(sharkDir, tolower(paste0("cached_", unique(datasets$datatype)[i], "_datasets.tsv"))), header = TRUE))
    },
    error = function(error) {
      datasets_cache = datasets_cache
    },
    warning = function(warning) {
      datasets_cache = datasets_cache
      }
    )
}

for(i in 1:length(unique(datasets$datatype))) {
  datasets_datatype = datasets %>%
    filter(datatype == unique(datatype)[i])
  
  if (!all(datasets_datatype$dataset_file_name %in% datasets_cache$dataset_file_name)) {
    
    write.table(datasets_datatype, file.path(sharkDir, tolower(paste0("cached_", unique(datasets_datatype$datatype), "_datasets.tsv"))), sep = "\t", row.names = F)
    
    print(paste0(unique(datasets_datatype$datatype), "-data has been updated since last download, will download a new version"))
    
    } else {
      print(paste0(unique(datasets_datatype$datatype), " datasets are up to date, no need to download a new version!"))
    }
}
```

## Download physchem data from SHARKdata 

```{r download_physchem_data, echo=FALSE, cache=TRUE, cache.extra=file.mtime(file.path(sharkDir, "cached_physicalchemical_datasets.tsv"))}
datasets_physchem = datasets %>%
  filter(datatype == "PhysicalChemical")

years_physchem = str_extract_all(datasets_physchem$dataset_name, "\\d{4}", simplify = T)

download_date_physchem = Sys.Date()

if(nrow(datasets_physchem) > 0) {
  data_shark_physchem_wide = data.frame()
  
  for(i in 1:nrow(datasets_physchem)) {
    temp = tempfile()
    
    download.file(paste("https://sharkdata.smhi.se/datasets/", datasets_physchem$dataset_name[i], "/shark_archive.zip", sep = ""), temp, mode="wb")
    
    data_ix = read.delim(unz(temp, "processed_data\\data.txt"))
    
    data_ix$dataset_name = datasets_physchem$dataset_name[i]
    
    data_shark_physchem_wide = plyr::rbind.fill(data_shark_physchem_wide, data_ix)
  }
}

# Convert DM to DD

coordinates = data_shark_physchem_wide %>%
  select(LATIT, LONGI)

f = function(x) as.double(substr(x, 1, 2)) + as.double(substring(x, 3)) / 60

coordinates = sapply(coordinates, f)

data_shark_physchem_wide$LATIT = coordinates[,1]
data_shark_physchem_wide$LONGI = coordinates[,2]

data_shark_physchem_wide = data_shark_physchem_wide %>%
  dplyr::rename("LATIT_DD" = LATIT,
                "LONGI_DD" = LONGI)

# Rename headers

translate_headers = read.delim(file.path(sharkDir, params$shark_translate), sep = "\t", header = TRUE)

names(data_shark_physchem_wide) = gsub("\\.", "-", names(data_shark_physchem_wide))

for(i in 1:nrow(translate_headers)) {
  names(data_shark_physchem_wide) = gsub(paste0("\\b", translate_headers$short[i], "\\b"), 
                                         translate_headers$internal_key[i], 
                                         names(data_shark_physchem_wide))
}

translate_stations = read_delim(file.path(sharkDir, params$shark_translate_station_names)) %>%
  mutate(official_name = coalesce(official_name, station_name))

data_shark_physchem_wide = data_shark_physchem_wide %>%
  left_join(translate_stations) %>%
  dplyr::select(-station_name) %>%
  dplyr::rename("station_name" = official_name)

if(nrow(datasets_physchem) > 0) {
  data_shark_physchem_long = data.frame()
  
  for(i in 1:nrow(datasets_physchem)) {
    temp = tempfile()
    
    download.file(paste("https://sharkdata.smhi.se/datasets/", datasets_physchem$dataset_name[i], "/shark_archive.zip", sep = ""), temp, mode="wb")
    
    data_ix = read.delim(unz(temp, "shark_data.txt"))
    
    data_shark_physchem_long = plyr::rbind.fill(data_shark_physchem_long, data_ix)
  }
}
```

## Download phytoplankton data from SHARKdata 

```{r download_phytoplankton_data, echo=FALSE, cache=TRUE, cache.extra=file.mtime(file.path(sharkDir, "cached_phytoplankton_datasets.tsv"))}
datasets_phytoplankton = datasets %>%
  filter(datatype == "Phytoplankton")

years_phytoplankton = str_extract_all(datasets_phytoplankton$dataset_name, "\\d{4}", simplify = T)

download_date_phytoplankton = Sys.Date()

if(nrow(datasets_phytoplankton) > 0) {
  data_shark_phytoplankton = data.frame()
  
  for(i in 1:nrow(datasets_phytoplankton)) {
    temp = tempfile()
    
    download.file(paste("https://sharkdata.smhi.se/datasets/", datasets_phytoplankton$dataset_name[i], "/shark_archive.zip", sep = ""), temp, mode="wb")
    
    data_ix = read.delim(unz(temp, "shark_data.txt"))
    
    data_shark_phytoplankton = plyr::rbind.fill(data_shark_phytoplankton, data_ix)
  }
}

# Get taxonomic information

# Dyntaxa Info

phylum = read.delim(file.path(sharkDir, params$shark_species), sep = "\t", header = TRUE) %>%
  dplyr::select(Taxon.id,
                Taxontyp,
                Gällande.namn,
                Klass,
                Ordning,
                Familj,
                Släkte,
                Taxonomisk.hierarki
                ) %>%
  filter(Taxontyp == "phylum")

shark_species_list = read.delim(file.path(sharkDir, params$shark_species), sep = "\t", header = TRUE) %>%
  dplyr::select(Taxon.id,
                Taxontyp,
                Gällande.namn,
                Klass,
                Ordning,
                Familj,
                Släkte,
                Taxonomisk.hierarki
                ) %>%
  dplyr::rename(dyntaxa_id=Taxon.id,
                "taxon_name" = Gällande.namn,
                "taxon_class" = Klass,
                "taxon_order" = Ordning,
                "taxon_family" = Familj,
                "taxon_genus" = Släkte) %>%
  mutate("taxon_kingdom" = word(Taxonomisk.hierarki, 1, sep = fixed(' - ')),
         "taxon_phylum" = NA) %>%
  dplyr::relocate(taxon_kingdom, .before = taxon_class) %>%
  dplyr::relocate(taxon_phylum, .before = taxon_class)

species = shark_species_list %>%
  filter(Taxontyp == "species") %>%
  select(taxon_name) %>%
  mutate(taxon_species = taxon_name)

species_form = shark_species_list %>%
  filter(Taxontyp == "variety" | Taxontyp == "form") %>%
  select(Taxontyp, taxon_name, -Taxontyp) %>%
  mutate("taxon_species" = word(taxon_name, 1,2))

species = rbind(species, species_form)

# Insert species

shark_species_list = shark_species_list %>%
  left_join(species) %>%
  dplyr::relocate(taxon_species, .after = taxon_genus) %>%
  dplyr::select(-Taxontyp)

# Insert phylum
for (i in 1:nrow(phylum)) {
  sel = phylum[i,3]
  for (j in 1:nrow(shark_species_list)) {
    if (grepl(sel, shark_species_list$Taxonomisk.hierarki[j])) {
      shark_species_list$taxon_phylum[j] = sel
    }
  }
}

shark_species_list = shark_species_list %>%
  dplyr::select(-Taxonomisk.hierarki,
                -taxon_name)

# WoRMS info

taxa_worms = read.delim(file.path(sharkDir, params$worms_species), sep = "\t", header = TRUE) %>%
  dplyr::select(aphia_id,
                rank,
                scientific_name,
                kingdom,
                phylum,
                class,
                order,
                family,
                genus) %>%
  dplyr::rename("taxon_name" = scientific_name,
                "worms_kingdom" = kingdom,
                "worms_phylum" = phylum,
                "worms_class" = class,
                "worms_order" = order,
                "worms_family" = family,
                "worms_genus" = genus) %>%
  distinct() 

worms_species = taxa_worms %>%
  filter(rank == "Species") %>%
  select(taxon_name) %>%
  mutate(worms_species = taxon_name)

worms_species_form = taxa_worms %>%
  filter(rank == "Variety" | rank == "Forma") %>%
  select(taxon_name) %>%
  mutate("worms_species" = word(taxon_name, 1,2))

worms_species = rbind(worms_species, worms_species_form)

# Insert species

taxa_worms = taxa_worms %>%
  left_join(worms_species) %>%
  dplyr::relocate(worms_species, .after = worms_genus) %>%
  dplyr::select(-rank, -taxon_name)

# Translate info

translate_taxa = read.delim(file.path(sharkDir, "translate_taxa.txt"), sep = "\t", header = TRUE) %>%
  filter(!taxon_name_from == "Coscinodiscophyceae") # Hardcoded to correct for PR2 5.01.
translate_aphiaid = read.delim(file.path(sharkDir, "translate_aphiaid.txt"), sep = "\t", header = TRUE)

# Translate incorrect names

# Join the data_shark_phytoplankton with the translate_taxa data frame
data_shark_phytoplankton <- left_join(data_shark_phytoplankton, translate_taxa, by = c("scientific_name" = "taxon_name_from"))

# Replace scientific_name with taxon_name_to where available, else keep original name
data_shark_phytoplankton <- data_shark_phytoplankton %>%
  mutate(scientific_name = if_else(!is.na(taxon_name_to), taxon_name_to, scientific_name)) %>%
  select(-taxon_name_to)

# Join the df with translate_aphiaid data frame and replace dyntaxa_id with dyntaxa_id_to where available
data_shark_phytoplankton <- left_join(data_shark_phytoplankton, translate_aphiaid, by = c("scientific_name" = "taxon_name_from")) %>%
  mutate(dyntaxa_id = if_else(!is.na(dyntaxa_id_to), dyntaxa_id_to, dyntaxa_id)) %>%
  select(-dyntaxa_id_to)

# Replace aphia_id with aphiaid_to where available
data_shark_phytoplankton <- data_shark_phytoplankton %>%
  mutate(aphia_id = if_else(!is.na(aphiaid_to), aphiaid_to, aphia_id)) %>%
  select(-aphiaid_to)

# Join taxonomy with data, hardcoded renaming of Coscinodiscophyceae and Mediophyceae

data_shark_phytoplankton = data_shark_phytoplankton %>%
  left_join(shark_species_list) %>%
  left_join(taxa_worms) %>%
  filter(!scientific_name == "Micromonas pusilla") %>%
  mutate(aphia_id = na_if(aphia_id, -9999)) %>%
  mutate(dyntaxa_id = na_if(dyntaxa_id, -9999)) %>%
  select(-Note.x,-Note.y) %>%
  mutate(taxon_class = gsub("^Bacillariophyta, classis incertae sedis$",
                            "Mediophyceae",
                            taxon_class)) %>%
  mutate(taxon_order = gsub("^Bacillariophyta, ordo incertae sedis$",
                            "Thalassiosirales",
                            taxon_order)) %>%
  mutate(taxon_family = gsub("^Bacillariophyta, familia incertae sedis$",
                            "Thalassiosiraceae",
                            taxon_family)) %>%
  mutate(taxon_class = gsub("^Noctilucea$",
                            "Noctilucophyceae",
                            taxon_class)) %>%
  mutate(taxon_class = gsub("^Coscinodiscophyceae$",
                            "Coscinodiscophyceae + Mediophyceae",
                            taxon_class)) %>%
  mutate(taxon_class = gsub("^Mediophyceae$",
                            "Coscinodiscophyceae + Mediophyceae",
                            taxon_class)) %>%
  mutate(new_class = if_else(taxon_class == "Coscinodiscophyceae + Mediophyceae", taxon_class, worms_class)) %>%
  dplyr::select(-worms_class) %>%
  dplyr::rename(worms_class = new_class) %>%
  dplyr::relocate(worms_class, .before = worms_order)

test = data_shark_phytoplankton %>%
  filter(taxon_class == "Coscinodiscophyceae + Mediophyceae")
```

## Download picoplankton data from SHARKdata 

```{r download_picoplankton_data, echo=FALSE, cache=TRUE, cache.extra=file.mtime(file.path(sharkDir, "cached_picoplankton_datasets.tsv"))}
datasets_picoplankton = datasets %>%
  filter(datatype == "Picoplankton")

years_picoplankton = str_extract_all(datasets_picoplankton$dataset_name, "\\d{4}", simplify = T)

download_date_picoplankton = Sys.Date()

if(nrow(datasets_picoplankton) > 0) {
  data_shark_picoplankton = data.frame()
  
  for(i in 1:nrow(datasets_picoplankton)) {
    temp = tempfile()
    
    download.file(paste("https://sharkdata.smhi.se/datasets/", datasets_picoplankton$dataset_name[i], "/shark_archive.zip", sep = ""), temp, mode="wb")
    
    data_ix = read.delim(unz(temp, "shark_data.txt"))
    
    data_shark_picoplankton = plyr::rbind.fill(data_shark_picoplankton, data_ix)
  }
}
```

## Download chlorophyll data from SHARKdata 

```{r download_chlorophyll_data, echo=FALSE, cache=TRUE, cache.extra=file.mtime(file.path(sharkDir, "cached_chlorophyll_datasets.tsv"))}
datasets_chlorophyll = datasets %>%
  filter(datatype == "Chlorophyll")

years_chlorophyll = str_extract_all(datasets_chlorophyll$dataset_name, "\\d{4}", simplify = T)

download_date_chlorophyll = Sys.Date()

if(nrow(datasets_chlorophyll) > 0) {
  data_shark_chlorophyll = data.frame()
  
  for(i in 1:nrow(datasets_chlorophyll)) {
    temp = tempfile()
    
    download.file(paste("https://sharkdata.smhi.se/datasets/", datasets_chlorophyll$dataset_name[i], "/shark_archive.zip", sep = ""), temp, mode="wb")
    
    data_ix = read.delim(unz(temp, "shark_data.txt"))
    
    data_shark_chlorophyll = plyr::rbind.fill(data_shark_chlorophyll, data_ix)
  }
}
```

## Write data files

```{r write_data, echo=FALSE}
write.table(data_shark_physchem_wide, 
            file.path(hydrographyDir, 
                      paste("physical_chemical_wide_", 
                            min(years_physchem), 
                            "_", 
                            max(years_physchem), 
                            "_", 
                            download_date_physchem, 
                            "_", 
                            params$encoding, 
                            ".txt", 
                            sep = "")), 
            na = "",
            sep = "\t", 
            fileEncoding = params$encoding,
            row.names = F)

write.table(data_shark_physchem_long, 
            file.path(hydrographyDir, 
                      paste("physical_chemical_long_", 
                            min(years_physchem), 
                            "_", 
                            max(years_physchem), 
                            "_", 
                            download_date_physchem, 
                            "_", 
                            params$encoding, 
                            ".txt", 
                            sep = "")), 
            na = "",
            sep = "\t", 
            fileEncoding = params$encoding,
            row.names = F)

write.table(data_shark_phytoplankton, 
            file.path(phytoplanktonDir, 
                      paste("phytoplankton_",
                            min(years_phytoplankton), 
                            "_", 
                            max(years_phytoplankton), 
                            "_", 
                            download_date_phytoplankton, 
                            "_",
                            params$encoding, 
                            ".txt", 
                            sep = "")), 
            na = "",
            sep = "\t", 
            fileEncoding = params$encoding,
            row.names = F)

write.table(data_shark_picoplankton, 
            file.path(picoplanktonDir, 
                      paste("picoplankton_", min(years_picoplankton), 
                            "_", 
                            max(years_picoplankton), 
                            "_", 
                            download_date_picoplankton, 
                            "_", 
                            params$encoding, 
                            ".txt", 
                            sep = "")), 
            na = "",
            sep = "\t", 
            fileEncoding = params$encoding,
            row.names = F)

write.table(data_shark_chlorophyll, 
            file.path(chlorophyllDir, 
                      paste("chlorophyll_", 
                            min(years_chlorophyll), 
                            "_", 
                            max(years_chlorophyll), 
                            "_", 
                            download_date_chlorophyll, 
                            "_", 
                            params$encoding, 
                            ".txt", 
                            sep = "")), 
            na = "",
            sep = "\t", 
            fileEncoding = params$encoding,
            row.names = F)
```

### Reproducibility

```{r reproducibility}
# Date time
Sys.time()
# Here we store the session info for this script
sessioninfo::session_info()
```